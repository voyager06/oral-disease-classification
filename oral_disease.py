# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjyL1xSSrtxDoHCvvmMCNEJESSRN4Ig1
"""

from google.colab import files
import zipfile
import os

# Upload the zip file
uploaded = files.upload()

# Assuming there's only one file uploaded, get its name
for file_name in uploaded.keys():
    zip_file_name = file_name

# Step 2: Extract the ZIP file
# Create a directory to extract the images
extract_path = "images"
os.makedirs(extract_path, exist_ok=True)

# Extract the contents of the ZIP file
with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Extracted images to {extract_path}")

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Rescaling

# For reproducibility
import numpy as np
import random
import os

seed = 123
random.seed(seed)
np.random.seed(seed)
tf.random.set_seed(seed)

train_dir = '/content/images/TRAIN'

test_dir = '/content/images/TEST'

# Hyperparameters
img_width, img_height = 224, 224
batch_size = 32
epochs = 5
num_classes = 2

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=(img_width, img_height),
    batch_size=batch_size
)
class_labels = train_dataset.class_names
print("Class Labels:", class_labels)

test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    test_dir,
    image_size=(img_width, img_height),
    batch_size=batch_size
)

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
])

train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.layers import Input

base_model = VGG16(weights=None,
                   include_top=False,
                   input_tensor=Input(shape=(224, 224, 3)))

base_model.summary()

# Load VGG16 with pre-trained ImageNet weights, excluding the top (fully connected) layers
base_model = VGG16(weights='imagenet',
                   include_top=False,
                   input_tensor=Input(shape=(img_width, img_height, 3)))
base_model.summary()

for layer in base_model.layers:
    layer.trainable = False

# Build the model
model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(4, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='sparse_categorical_crossentropy',  # or 'categorical_crossentropy' if labels are one-hot encoded
              metrics=['accuracy'])

history = model.fit(
    train_dataset,

    epochs=10,
)

model.save('/content/oral_disease_model.h5')
print("Model saved as 'oral_disease_model.h5'")

# Reload the model for prediction
model = tf.keras.models.load_model('/content/oral_disease_model.h5')
print("Model loaded successfully")

test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

y_train_true = np.concatenate([y for x, y in train_dataset], axis=0)
y_train_pred = model.predict(train_dataset)
y_train_pred = np.argmax(y_train_pred, axis=1)

y_test_true = np.concatenate([y for x, y in test_dataset], axis=0)
y_test_pred = model.predict(test_dataset)
y_test_pred = np.argmax(y_test_pred, axis=1)

from sklearn.metrics import confusion_matrix

# Confusion matrices
cm_train = confusion_matrix(y_train_true, y_train_pred)

cm_test = confusion_matrix(y_test_true, y_test_pred)


import matplotlib.pyplot as plt
import seaborn as sns

# Set up the figure
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Train Confusion Matrix
sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Train Confusion Matrix')
axes[0].set_xlabel('Predicted Labels')
axes[0].set_ylabel('True Labels')

# Test Confusion Matrix
sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=axes[2])
axes[1].set_title('Test Confusion Matrix')
axes[1].set_xlabel('Predicted Labels')
axes[1].set_ylabel('True Labels')

# Adjust layout
plt.tight_layout()
plt.show()

import cv2
import numpy as np
import tensorflow as tf

# Define the image path
image_path = "/content/images/TEST/Gingivitis/105_1.jpg"

# Load and preprocess the image
image = cv2.imread(image_path)
if image is None:
    raise ValueError(f"Image not found at path: {image_path}")

image_resized = cv2.resize(image, (224, 224))
image_normalized = image_resized / 255.0
image_batch = np.expand_dims(image_normalized, axis=0)

# Load the trained model
model = tf.keras.models.load_model('/content/oral_disease_model.h5')

# Define class labels
class_labels = ['Caries', 'Gingivitis']

# Predict
predictions = model.predict(image_batch)
predicted_index = np.argmax(predictions[0])
predicted_label = class_labels[predicted_index]
confidence = predictions[0][predicted_index]

print(f"Predicted Class: {predicted_label}, Confidence: {confidence:.2f}")

plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title(f"Prediction: {predicted_label} ({confidence * 100:.2f}%)")
plt.axis('off')
plt.show()





